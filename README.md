# babyGPT
Minimalist implementation of GPT using Pytorch. Based on a fork of https://github.com/karpathy/minGPT. 
In babyGPT, we use Pytorch's built-in `TransformerEncoder` class instead of writing one ourselves. We also simplify the optimizer config of minGPT to be dead simple. 
This is simply an academic exercise. 
